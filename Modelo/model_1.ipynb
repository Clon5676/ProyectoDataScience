{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf8ef34",
   "metadata": {},
   "source": [
    "# Model Interation 1\n",
    "Esta es la primera iteracion del modelo luego de completar el model baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450f3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cdaa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/vbht61m97rg6wrrbgs95_9k00000gn/T/ipykernel_89962/477908195.py:2: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../Modelo/gamesWcategoricas.csv')  # ajust√° el path si hace falta\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV desde local\n",
    "df = pd.read_csv('../Modelo/gamesWcategoricas.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0cd8da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos de 'Release date':\n",
      "[2008 2017 2021 2020 2022 2014 2019 2016 2018 2010]\n",
      "\n",
      "Tipo de 'Release date': int64\n",
      "\n",
      "Valores √∫nicos de 'Price':\n",
      "[19.99  0.99  4.99  5.99  0.   10.99  9.99 14.99  3.99 23.99]\n",
      "\n",
      "Tipo de 'Price': float64\n"
     ]
    }
   ],
   "source": [
    "# Revisar columnas clave para ingenier√≠a\n",
    "print(\"Valores √∫nicos de 'Release date':\")\n",
    "print(df['Release date'].unique()[:10])  # ver algunos\n",
    "\n",
    "print(\"\\nTipo de 'Release date':\", df['Release date'].dtype)\n",
    "\n",
    "print(\"\\nValores √∫nicos de 'Price':\")\n",
    "print(df['Price'].unique()[:10])  # ver algunos\n",
    "\n",
    "print(\"\\nTipo de 'Price':\", df['Price'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233475cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   release_year  Price price_range\n",
      "0          2008  19.99      medium\n",
      "1          2017   0.99         low\n",
      "2          2021   4.99         low\n",
      "3          2020   5.99         low\n",
      "4          2020   0.00        free\n",
      "\n",
      "Distribuci√≥n de price_range:\n",
      "price_range\n",
      "low       66873\n",
      "free      23247\n",
      "medium    19066\n",
      "high       2266\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Feature: release_year\n",
    "df['release_year'] = df['Release date']\n",
    "\n",
    "# Feature: price_range\n",
    "def clasificar_precio(precio):\n",
    "    if precio == 0:\n",
    "        return 'free'\n",
    "    elif precio < 10:\n",
    "        return 'low'\n",
    "    elif precio < 30:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "df['price_range'] = df['Price'].apply(clasificar_precio)\n",
    "\n",
    "# Verificamos\n",
    "print(df[['release_year', 'Price', 'price_range']].head())\n",
    "print(\"\\nDistribuci√≥n de price_range:\")\n",
    "print(df['price_range'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a080156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar One-Hot Encoding a price_range\n",
    "df_encoded = pd.get_dummies(df, columns=['price_range'], prefix='price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fce41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables predictoras\n",
    "X = df_encoded.drop(columns=['Estimated owners'])  # o el nombre de tu target\n",
    "\n",
    "# Variable objetivo\n",
    "y = df_encoded['Estimated owners']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51472ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name              object\n",
      "About the game    object\n",
      "Reviews           object\n",
      "Header image      object\n",
      "Website           object\n",
      "Support url       object\n",
      "Support email     object\n",
      "Metacritic url    object\n",
      "Notes             object\n",
      "Developers        object\n",
      "Publishers        object\n",
      "Screenshots       object\n",
      "Movies            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verific√° qu√© columnas no son num√©ricas\n",
    "print(X.dtypes[X.dtypes == 'object'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "871afe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas tipo texto que no fueron codificadas\n",
    "columnas_objetables = X.select_dtypes(include='object').columns\n",
    "X = X.drop(columns=columnas_objetables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fbf4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "626d464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisvillela/Desktop/UFM/2025-1/Data science/ProyectoDataScience/env/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Divisi√≥n 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entrenamiento\n",
    "model = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')  # para multiclase\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_iter1 = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712dcce3",
   "metadata": {},
   "source": [
    "# Evaluaci√≥n del modelo de Iteraci√≥n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2a0e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Matriz de Confusi√≥n (Iteraci√≥n 1):\n",
      "[[ 3398  1035     1     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [  206 13568   179    33    12     6     3     3     3     2     1     0\n",
      "      0]\n",
      " [    1  1339   245    58    24    21     3     1     0     1     0     0\n",
      "      0]\n",
      " [    0   495   149    59    51    28     8     0     1     2     0     0\n",
      "      0]\n",
      " [    0   219   105    68    80    62    12     4     0     1     0     1\n",
      "      0]\n",
      " [    0    76    45    37    74   151    23    13     1     2     0     0\n",
      "      0]\n",
      " [    0     9     8     4    11    75    47    15     8     4     0     0\n",
      "      0]\n",
      " [    0     7     1     1     4    25    25    31    16     5     2     0\n",
      "      0]\n",
      " [    0     0     0     0     0     3     4    25    19     7     1     1\n",
      "      0]\n",
      " [    0     0     0     0     0     1     1     1     8     2     1     0\n",
      "      0]\n",
      " [    0     0     0     0     1     0     0     1     2     1     0     0\n",
      "      1]\n",
      " [    0     0     0     0     0     0     0     0     1     1     0     1\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]]\n",
      "\n",
      "üìå Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85      4434\n",
      "       20000       0.81      0.97      0.88     14016\n",
      "       50000       0.33      0.14      0.20      1693\n",
      "      100000       0.23      0.07      0.11       793\n",
      "      200000       0.31      0.14      0.20       552\n",
      "      500000       0.41      0.36      0.38       422\n",
      "     1000000       0.37      0.26      0.31       181\n",
      "     2000000       0.33      0.26      0.29       117\n",
      "     5000000       0.32      0.32      0.32        60\n",
      "    10000000       0.07      0.14      0.10        14\n",
      "    20000000       0.00      0.00      0.00         6\n",
      "    50000000       0.33      0.33      0.33         3\n",
      "   100000000       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.79     22291\n",
      "   macro avg       0.34      0.29      0.31     22291\n",
      "weighted avg       0.75      0.79      0.76     22291\n",
      "\n",
      "‚úÖ Precision (macro): 0.343\n",
      "‚úÖ Recall (macro): 0.29\n",
      "‚úÖ F1 Score (macro): 0.305\n",
      "‚úÖ Precision (weighted): 0.751\n",
      "‚úÖ Recall (weighted): 0.79\n",
      "‚úÖ F1 Score (weighted): 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisvillela/Desktop/UFM/2025-1/Data science/ProyectoDataScience/env/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/luisvillela/Desktop/UFM/2025-1/Data science/ProyectoDataScience/env/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/luisvillela/Desktop/UFM/2025-1/Data science/ProyectoDataScience/env/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/luisvillela/Desktop/UFM/2025-1/Data science/ProyectoDataScience/env/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/luisvillela/Desktop/UFM/2025-1/Data science/ProyectoDataScience/env/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# üìä Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred_iter1)\n",
    "print(\"üìå Matriz de Confusi√≥n (Iteraci√≥n 1):\")\n",
    "print(cm)\n",
    "\n",
    "# üìã Reporte general\n",
    "print(\"\\nüìå Reporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred_iter1))\n",
    "\n",
    "# ‚úÖ M√©tricas macro y weighted\n",
    "print(\"‚úÖ Precision (macro):\", round(precision_score(y_test, y_pred_iter1, average='macro'), 3))\n",
    "print(\"‚úÖ Recall (macro):\", round(recall_score(y_test, y_pred_iter1, average='macro'), 3))\n",
    "print(\"‚úÖ F1 Score (macro):\", round(f1_score(y_test, y_pred_iter1, average='macro'), 3))\n",
    "\n",
    "print(\"‚úÖ Precision (weighted):\", round(precision_score(y_test, y_pred_iter1, average='weighted'), 3))\n",
    "print(\"‚úÖ Recall (weighted):\", round(recall_score(y_test, y_pred_iter1, average='weighted'), 3))\n",
    "print(\"‚úÖ F1 Score (weighted):\", round(f1_score(y_test, y_pred_iter1, average='weighted'), 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
